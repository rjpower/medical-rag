{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/mambaforge/envs/tensorml/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datasets\n",
    "import torch\n",
    "import transformers\n",
    "import typing\n",
    "import requests\n",
    "import tqdm\n",
    "import pathlib\n",
    "import json\n",
    "\n",
    "import medrag.utils\n",
    "import medrag.finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67d0ceecd2c84394a0215f3816528d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/mambaforge/envs/tensorml/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "retriever = medrag.utils.RetrievalSystem(corpus_name=\"Textbooks\", db_dir=\"./corpus\")\n",
    "# finetune = medrag.utils.RetrievalSystem(retriever_name=\"./cache/medcpt-embedding-model\", corpus_name=\"Textbooks\", db_dir=\"./corpus\")\n",
    "\n",
    "benchmark_df = medrag.finetune.load_benchmark_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/mambaforge/envs/tensorml/lib/python3.11/site-packages/datasets/load.py:1491: FutureWarning: The repository for bigbio/med_qa contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/bigbio/med_qa\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meta_info</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>options</th>\n",
       "      <th>dataset</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>step2&amp;3</td>\n",
       "      <td>A 23-year-old pregnant woman at 22 weeks gestation presents with burning upon urination. She states it started 1 day ago and has been worsening despite drinking more water and taking cranberry extract. She otherwise feels well and is followed by a doctor for her pregnancy. Her temperature is 97.7°F (36.5°C), blood pressure is 122/77 mmHg, pulse is 80/min, respirations are 19/min, and oxygen saturation is 98% on room air. Physical exam is notable for an absence of costovertebral angle tenderness and a gravid uterus. Which of the following is the best treatment for this patient?</td>\n",
       "      <td>E</td>\n",
       "      <td>Nitrofurantoin</td>\n",
       "      <td>{'A': 'Ampicillin', 'B': 'Ceftriaxone', 'C': 'Ciprofloxacin', 'D': 'Doxycycline', 'E': 'Nitrofurantoin'}</td>\n",
       "      <td>medqa</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>step2&amp;3</td>\n",
       "      <td>A 3-month-old baby died suddenly at night while asleep. His mother noticed that he had died only after she awoke in the morning. No cause of death was determined based on the autopsy. Which of the following precautions could have prevented the death of the baby?</td>\n",
       "      <td>A</td>\n",
       "      <td>Placing the infant in a supine position on a firm mattress while sleeping</td>\n",
       "      <td>{'A': 'Placing the infant in a supine position on a firm mattress while sleeping', 'B': 'Routine postnatal electrocardiogram (ECG)', 'C': 'Keeping the infant covered and maintaining a high room temperature', 'D': 'Application of a device to maintain the sleeping position', 'E': 'Avoiding pacifier use during sleep'}</td>\n",
       "      <td>medqa</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>step1</td>\n",
       "      <td>A mother brings her 3-week-old infant to the pediatrician's office because she is concerned about his feeding habits. He was born without complications and has not had any medical problems up until this time. However, for the past 4 days, he has been fussy, is regurgitating all of his feeds, and his vomit is yellow in color. On physical exam, the child's abdomen is minimally distended but no other abnormalities are appreciated. Which of the following embryologic errors could account for this presentation?</td>\n",
       "      <td>A</td>\n",
       "      <td>Abnormal migration of ventral pancreatic bud</td>\n",
       "      <td>{'A': 'Abnormal migration of ventral pancreatic bud', 'B': 'Complete failure of proximal duodenum to recanalize', 'C': 'Error in neural crest cell migration', 'D': 'Abnormal hypertrophy of the pylorus', 'E': 'Failure of lateral body folds to move ventrally and fuse in the midline'}</td>\n",
       "      <td>medqa</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  meta_info  \\\n",
       "0   step2&3   \n",
       "1   step2&3   \n",
       "2     step1   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  question  \\\n",
       "0  A 23-year-old pregnant woman at 22 weeks gestation presents with burning upon urination. She states it started 1 day ago and has been worsening despite drinking more water and taking cranberry extract. She otherwise feels well and is followed by a doctor for her pregnancy. Her temperature is 97.7°F (36.5°C), blood pressure is 122/77 mmHg, pulse is 80/min, respirations are 19/min, and oxygen saturation is 98% on room air. Physical exam is notable for an absence of costovertebral angle tenderness and a gravid uterus. Which of the following is the best treatment for this patient?   \n",
       "1                                                                                                                                                                                                                                                                                                                                   A 3-month-old baby died suddenly at night while asleep. His mother noticed that he had died only after she awoke in the morning. No cause of death was determined based on the autopsy. Which of the following precautions could have prevented the death of the baby?   \n",
       "2                                                                           A mother brings her 3-week-old infant to the pediatrician's office because she is concerned about his feeding habits. He was born without complications and has not had any medical problems up until this time. However, for the past 4 days, he has been fussy, is regurgitating all of his feeds, and his vomit is yellow in color. On physical exam, the child's abdomen is minimally distended but no other abnormalities are appreciated. Which of the following embryologic errors could account for this presentation?   \n",
       "\n",
       "  answer  \\\n",
       "0      E   \n",
       "1      A   \n",
       "2      A   \n",
       "\n",
       "                                                                 answer_text  \\\n",
       "0                                                             Nitrofurantoin   \n",
       "1  Placing the infant in a supine position on a firm mattress while sleeping   \n",
       "2                               Abnormal migration of ventral pancreatic bud   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                        options  \\\n",
       "0                                                                                                                                                                                                                      {'A': 'Ampicillin', 'B': 'Ceftriaxone', 'C': 'Ciprofloxacin', 'D': 'Doxycycline', 'E': 'Nitrofurantoin'}   \n",
       "1  {'A': 'Placing the infant in a supine position on a firm mattress while sleeping', 'B': 'Routine postnatal electrocardiogram (ECG)', 'C': 'Keeping the infant covered and maintaining a high room temperature', 'D': 'Application of a device to maintain the sleeping position', 'E': 'Avoiding pacifier use during sleep'}   \n",
       "2                                    {'A': 'Abnormal migration of ventral pancreatic bud', 'B': 'Complete failure of proximal duodenum to recanalize', 'C': 'Error in neural crest cell migration', 'D': 'Abnormal hypertrophy of the pylorus', 'E': 'Failure of lateral body folds to move ventrally and fuse in the midline'}   \n",
       "\n",
       "  dataset  split  \n",
       "0   medqa  train  \n",
       "1   medqa  train  \n",
       "2   medqa  train  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_medqa():\n",
    "  medqa = datasets.load_dataset(\"bigbio/med_qa\")\n",
    "\n",
    "  splits = []\n",
    "  for split_name in medqa.keys():\n",
    "    split = medqa[split_name]\n",
    "    split = split.to_pandas()\n",
    "    split = split.rename(columns={\"answer\": \"answer_text\"})\n",
    "    split = split.rename(columns={\"answer_idx\": \"answer\"})\n",
    "\n",
    "    # replace {'key': 'A', 'value': 'xyz' } in the options column with {'a': 'xyz', ...}\n",
    "    def replace_keys_with_letters(options):\n",
    "        return {opt[\"key\"]: opt[\"value\"] for opt in options}\n",
    "\n",
    "    split[\"dataset\"] = \"medqa\"\n",
    "    split[\"options\"] = split[\"options\"].apply(replace_keys_with_letters)\n",
    "    split[\"split\"] = split_name\n",
    "    splits.append(split)\n",
    "\n",
    "  medqa = pd.concat(splits)\n",
    "  return medqa\n",
    "  \n",
    "medqa = load_medqa()\n",
    "medqa.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52f18d8db3af413e99864cdcb80fcaf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# Load Llama in bfloat16 precision\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3-8B-Instruct\", torch_dtype=torch.bfloat16).to(\"cuda\")\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B-Instruct\", padding_side=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|begin_of_text|><|start_header_id|>system<|end_header_id|>You are a helpful medical expert, and your task is to answer a multi-choice medical question.\n",
      "Your responses will be used for research purposes only, so please have a definite answer.\n",
      "Answer using a only single letter, A, B, C, D, or E. Do not explain further.\n",
      "\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>Here is some useful context for your question: Question: A junior orthopaedic surgery resident is completing a carpal tunnel repair with the department chairman as the attending physician. During the case, the resident inadvertently cuts a flexor tendon. The tendon is repaired without complication. The attending tells the resident that the patient will do fine, and there is no need to report this minor complication that will not harm the patient, as he does not want to make the patient worry unnecessarily. He tells the resident to leave this complication out of the operative report. Which of the following is the correct next action for the resident to take?\n",
      "\n",
      "A: Disclose the error to the patient and put it in the operative report\n",
      "B: Tell the attending that he cannot fail to disclose this mistake\n",
      "C: Report the physician to the ethics committee\n",
      "D: Refuse to dictate the operative report\n",
      "\n",
      "Answer (A, B, C, D, or E): <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "A<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "# make a multiple-choice question from a row.\n",
    "import typing\n",
    "\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are a helpful medical expert, and your task is to answer a multi-choice medical question.\\n\"\n",
    "    \"Your responses will be used for research purposes only, so please have a definite answer.\\n\"\n",
    "    \"Answer using a only single letter, A, B, C, D, or E. Do not explain further.\\n\\n\"\n",
    ")\n",
    "\n",
    "def build_prompt(record: typing.Dict, context: str = \"\"):\n",
    "    question = record[\"question\"]\n",
    "    options = record[\"options\"]\n",
    "    options = \"\\n\".join(f\"{key}: {value}\" for key, value in options.items())\n",
    "    prompt = (\n",
    "        \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\"\n",
    "        + SYSTEM_PROMPT\n",
    "        + \"<|eot_id|><|start_header_id|>user<|end_header_id|>\"\n",
    "        + \"Here is some useful context for your question: \"\n",
    "        + context\n",
    "        + f\"Question: {question}\\n\\n\"\n",
    "        + options\n",
    "        + \"\\n\\nAnswer (A, B, C, D, or E): \"\n",
    "        + \"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "tokens = tokenizer([build_prompt(benchmark_df.iloc[0])], return_tensors=\"pt\").to(\"cuda\")\n",
    "output = model.generate(\n",
    "    **tokens,\n",
    "    max_new_tokens=5,\n",
    "    output_logits=True,\n",
    "    return_dict_in_generate=True,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "output = tokenizer.decode(output[\"sequences\"][0])\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>dataset</th>\n",
       "      <th>question</th>\n",
       "      <th>options</th>\n",
       "      <th>reference</th>\n",
       "      <th>logits</th>\n",
       "      <th>probits</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>medmcqa</td>\n",
       "      <td>Dicor is</td>\n",
       "      <td>{'A': 'Castable ceramic', 'B': 'Metavite', 'C': 'Vitallium', 'D': 'Vita ceramic'}</td>\n",
       "      <td>A</td>\n",
       "      <td>[34.75, 27.375, 25.75, 29.5, 20.375]</td>\n",
       "      <td>[0.9940376, 0.00062298996, 0.00012267398, 0.0052162306, 5.680933e-07]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>medmcqa</td>\n",
       "      <td>A 42 years old woman from a dry state who ingested rye for long time presented with complaints of weakness in both lower limbs, nausea and fatigue. Over due course of time, she is completely unable to walk. What is the most likely cause?</td>\n",
       "      <td>{'A': 'Argemone mexicana', 'B': 'Amanita', 'C': 'Ergot alkaloids', 'D': 'Lathyrus sativus'}</td>\n",
       "      <td>D</td>\n",
       "      <td>[29.75, 30.625, 33.5, 28.625, 23.75]</td>\n",
       "      <td>[0.021622984, 0.051870838, 0.91943264, 0.0070199547, 5.3598014e-05]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>medqa</td>\n",
       "      <td>A 4-year-old child is rushed to the emergency department after developing sudden abdominal pain followed by nausea, vomiting, and dark, almost black-colored stool. Prior to the onset of symptoms, he was seen playing with his mother’s purse containing a bottle of vitamin supplements, which she takes for chronic microcytic anemia. Which of the following medications is the treatment for this patient's intoxication?</td>\n",
       "      <td>{'A': 'Dimercaprol', 'B': 'Deferoxamine', 'C': 'Protamine', 'D': 'Succimer'}</td>\n",
       "      <td>B</td>\n",
       "      <td>[32.5, 33.0, 27.0, 27.75, 23.0]</td>\n",
       "      <td>[0.3757231, 0.61946267, 0.0015354945, 0.0032506417, 2.8123563e-05]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>medmcqa</td>\n",
       "      <td>A 50-year-old male presented with complains of ptosis, difficulty in chewing and occasional difficulty in swallowing. There is no history of diplopia or visual loss. On examination, there is symmetric ptosis and mild restriction of extraocular muscle movement with finger abduction test 60deg. Nerve conduction study shows decremental response in orbicularis only. ERG revealed a myopathic pattern. Anti-AchR radioimmunoassay was negative. The most probable diagnosis would be:</td>\n",
       "      <td>{'A': 'Ocular myasthenia gravis', 'B': 'Generalized myasthenia gravis', 'C': 'As anti-ACHR is negative you will consider an alternative diagnosis', 'D': 'Chronic progressive external ophthalmoplegia (CPEO)'}</td>\n",
       "      <td>B</td>\n",
       "      <td>[29.875, 29.875, 30.25, 32.75, 22.375]</td>\n",
       "      <td>[0.04721219, 0.04721219, 0.06869333, 0.8368561, 2.6112326e-05]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>medmcqa</td>\n",
       "      <td>Noise induced hearing toss inosto affects:</td>\n",
       "      <td>{'A': 'Inner hair cell', 'B': 'Outer hair cell', 'C': 'Macula', 'D': 'Cupula'}</td>\n",
       "      <td>B</td>\n",
       "      <td>[28.25, 33.75, 24.75, 22.25, 20.625]</td>\n",
       "      <td>[0.0040695886, 0.9957955, 0.00012289092, 1.0087501e-05, 1.986347e-06]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  answer  dataset  \\\n",
       "0      A  medmcqa   \n",
       "1      C  medmcqa   \n",
       "2      B    medqa   \n",
       "3      D  medmcqa   \n",
       "4      B  medmcqa   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        question  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Dicor is   \n",
       "1                                                                                                                                                                                                                                                  A 42 years old woman from a dry state who ingested rye for long time presented with complaints of weakness in both lower limbs, nausea and fatigue. Over due course of time, she is completely unable to walk. What is the most likely cause?   \n",
       "2                                                                A 4-year-old child is rushed to the emergency department after developing sudden abdominal pain followed by nausea, vomiting, and dark, almost black-colored stool. Prior to the onset of symptoms, he was seen playing with his mother’s purse containing a bottle of vitamin supplements, which she takes for chronic microcytic anemia. Which of the following medications is the treatment for this patient's intoxication?   \n",
       "3  A 50-year-old male presented with complains of ptosis, difficulty in chewing and occasional difficulty in swallowing. There is no history of diplopia or visual loss. On examination, there is symmetric ptosis and mild restriction of extraocular muscle movement with finger abduction test 60deg. Nerve conduction study shows decremental response in orbicularis only. ERG revealed a myopathic pattern. Anti-AchR radioimmunoassay was negative. The most probable diagnosis would be:   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                     Noise induced hearing toss inosto affects:   \n",
       "\n",
       "                                                                                                                                                                                                           options  \\\n",
       "0                                                                                                                                {'A': 'Castable ceramic', 'B': 'Metavite', 'C': 'Vitallium', 'D': 'Vita ceramic'}   \n",
       "1                                                                                                                      {'A': 'Argemone mexicana', 'B': 'Amanita', 'C': 'Ergot alkaloids', 'D': 'Lathyrus sativus'}   \n",
       "2                                                                                                                                     {'A': 'Dimercaprol', 'B': 'Deferoxamine', 'C': 'Protamine', 'D': 'Succimer'}   \n",
       "3  {'A': 'Ocular myasthenia gravis', 'B': 'Generalized myasthenia gravis', 'C': 'As anti-ACHR is negative you will consider an alternative diagnosis', 'D': 'Chronic progressive external ophthalmoplegia (CPEO)'}   \n",
       "4                                                                                                                                   {'A': 'Inner hair cell', 'B': 'Outer hair cell', 'C': 'Macula', 'D': 'Cupula'}   \n",
       "\n",
       "  reference                                  logits  \\\n",
       "0         A    [34.75, 27.375, 25.75, 29.5, 20.375]   \n",
       "1         D    [29.75, 30.625, 33.5, 28.625, 23.75]   \n",
       "2         B         [32.5, 33.0, 27.0, 27.75, 23.0]   \n",
       "3         B  [29.875, 29.875, 30.25, 32.75, 22.375]   \n",
       "4         B    [28.25, 33.75, 24.75, 22.25, 20.625]   \n",
       "\n",
       "                                                                 probits  \\\n",
       "0  [0.9940376, 0.00062298996, 0.00012267398, 0.0052162306, 5.680933e-07]   \n",
       "1    [0.021622984, 0.051870838, 0.91943264, 0.0070199547, 5.3598014e-05]   \n",
       "2     [0.3757231, 0.61946267, 0.0015354945, 0.0032506417, 2.8123563e-05]   \n",
       "3         [0.04721219, 0.04721219, 0.06869333, 0.8368561, 2.6112326e-05]   \n",
       "4  [0.0040695886, 0.9957955, 0.00012289092, 1.0087501e-05, 1.986347e-06]   \n",
       "\n",
       "   correct  \n",
       "0     True  \n",
       "1    False  \n",
       "2     True  \n",
       "3    False  \n",
       "4     True  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try it out\n",
    "sample_df = benchmark_df.sample(16, random_state=42)\n",
    "outputs = batch_predict(model, tokenizer, sample_df.to_dict(\"records\"))\n",
    "pd.DataFrame(outputs).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [02:14<00:00, 30.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# Find the documents that are most strongly correlated with a sample of N questions.\n",
    "# We sample from these \"good\" documents to determine a set of documents to evaluate\n",
    "# against our question set.\n",
    "import collections\n",
    "import tqdm\n",
    "\n",
    "def find_top_documents(df, num_questions, results_per_question=10):\n",
    "  sample_df = df.sample(min(num_questions, len(df)), random_state=42)\n",
    "  result_counts = collections.defaultdict(int)\n",
    "  for question in tqdm.tqdm(sample_df['question']):\n",
    "    results, scores = retriever.retrieve(question, k=results_per_question)\n",
    "    for result in results:\n",
    "      result_counts[result['id']] += 1 \n",
    "  return result_counts\n",
    "\n",
    "top_documents = find_top_documents(medqa, num_questions=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('InternalMed_Harrison_19190', 1006),\n",
       " ('InternalMed_Harrison_615', 508),\n",
       " ('InternalMed_Harrison_1673', 352),\n",
       " ('InternalMed_Harrison_12', 333),\n",
       " ('InternalMed_Harrison_1704', 272),\n",
       " ('InternalMed_Harrison_2955', 258),\n",
       " ('InternalMed_Harrison_3641', 208),\n",
       " ('InternalMed_Harrison_201', 194),\n",
       " ('Pharmacology_Katzung_2624', 194),\n",
       " ('InternalMed_Harrison_2763', 157)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what are the top overall documents?\n",
    "sorted(top_documents.items(), key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ef4a2d37490>]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the distribution of sorted document counts\n",
    "# doc index on the x axis, count on the y\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(sorted(top_documents.values(), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As average levels of health vary across regions and countries, so too do they vary within countries (Fig. 13e-4). Indeed, disparities within countries are often greater than those between high-income and low-income countries. For example, if lowand middle-income countries could reduce their overall childhood mortality rate to that of the richest one-fifth of their populations, global childhood mortality could be decreased by 40%. Disparities in health are mostly a result of social and economic factors such as daily living conditions, access to resources, and ability to participate in life-affecting decisions. In most countries, the health care sector actually tends to exacerbate health inequalities (the “inverse-care law”); because of neglect and discrimination, poor and marginalized communities are much less likely to benefit from public health services than those that are better off. Reforming health systems toward people-centered primary care provides an opportunity to reverse\n"
     ]
    }
   ],
   "source": [
    "# What's does this Harrison document look like?\n",
    "print(retriever.get_document_by_id('textbooks', 'InternalMed_Harrison_986'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take the top N documents from our top document set and evaluate how well\n",
    "# they improve the performance on a sample of questions. We will then select the\n",
    "# document that improves the performance the most on our set.\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "NUM_SAMPLE_QUESTIONS = min(len(medqa), 50)\n",
    "NUM_SAMPLE_DOCUMENTS = 10\n",
    "\n",
    "@dataclass\n",
    "class Document:\n",
    "    id: str\n",
    "    content: str\n",
    "\n",
    "\n",
    "def evaluate_document(\n",
    "    model: transformers.PreTrainedModel,\n",
    "    tokenizer: transformers.PreTrainedTokenizer,\n",
    "    doc: Document,\n",
    "    df: pd.DataFrame,\n",
    "):\n",
    "    sample_questions = df.sample(NUM_SAMPLE_QUESTIONS, random_state=42).to_dict(\"records\")\n",
    "    results = batch_predict(model, tokenizer, sample_questions, context=[doc.content])\n",
    "    for r in results:\n",
    "        r[\"context\"] = doc.id\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def evaluate_documents(\n",
    "    model: transformers.PreTrainedModel,\n",
    "    tokenizer: transformers.PreTrainedTokenizer,\n",
    "    docs: typing.List[Document],\n",
    "    df: pd.DataFrame,\n",
    "):\n",
    "    # evaluate for each doc and concat the results into a single dataframe\n",
    "    df = pd.concat(\n",
    "        [evaluate_document(model, tokenizer, doc, df) for doc in tqdm.tqdm(docs)]\n",
    "    )\n",
    "    return df\n",
    "\n",
    "top = sorted(top_documents.items(), key=lambda x: x[1], reverse=True)[\n",
    "    :NUM_SAMPLE_DOCUMENTS\n",
    "]\n",
    "top = [\n",
    "    Document(id=id, content=retriever.get_document_by_id(\"textbooks\", id))\n",
    "    for id, _ in top\n",
    "]\n",
    "\n",
    "combined = evaluate_documents(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    top,\n",
    "    medqa,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>InternalMed_Harrison_12</th>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>InternalMed_Harrison_1673</th>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>InternalMed_Harrison_1704</th>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>InternalMed_Harrison_19190</th>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>InternalMed_Harrison_201</th>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>InternalMed_Harrison_2763</th>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>InternalMed_Harrison_2955</th>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>InternalMed_Harrison_3641</th>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>InternalMed_Harrison_615</th>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pharmacology_Katzung_2624</th>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            correct\n",
       "context                            \n",
       "InternalMed_Harrison_12        0.50\n",
       "InternalMed_Harrison_1673      0.46\n",
       "InternalMed_Harrison_1704      0.52\n",
       "InternalMed_Harrison_19190     0.46\n",
       "InternalMed_Harrison_201       0.50\n",
       "InternalMed_Harrison_2763      0.48\n",
       "InternalMed_Harrison_2955      0.50\n",
       "InternalMed_Harrison_3641      0.46\n",
       "InternalMed_Harrison_615       0.48\n",
       "Pharmacology_Katzung_2624      0.34"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.groupby('context').agg({'correct': 'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "      <th>dataset</th>\n",
       "      <th>question</th>\n",
       "      <th>options</th>\n",
       "      <th>reference</th>\n",
       "      <th>logits</th>\n",
       "      <th>probits</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D</td>\n",
       "      <td>medqa</td>\n",
       "      <td>An investigator is studying the frequency of p...</td>\n",
       "      <td>{'A': '30%', 'B': '15%', 'C': '95%', 'D': '99%...</td>\n",
       "      <td>B</td>\n",
       "      <td>[27.125, 27.25, 28.125, 27.125, 26.875]</td>\n",
       "      <td>[0.15082432, 0.17090634, 0.409983, 0.15082432,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D</td>\n",
       "      <td>medqa</td>\n",
       "      <td>A 37-year-old woman presents to the occupation...</td>\n",
       "      <td>{'A': 'Type I–anaphylactic hypersensitivity re...</td>\n",
       "      <td>D</td>\n",
       "      <td>[24.0, 23.5, 22.875, 34.0, 23.25]</td>\n",
       "      <td>[4.539498e-05, 2.7533446e-05, 1.4737591e-05, 0...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>medqa</td>\n",
       "      <td>A 49-year-old man comes to the hospital for a ...</td>\n",
       "      <td>{'A': 'Amylase of 200 U/L', 'B': 'Lymphocytosi...</td>\n",
       "      <td>E</td>\n",
       "      <td>[29.0, 29.875, 28.75, 28.25, 29.0]</td>\n",
       "      <td>[0.17698982, 0.42457652, 0.13783981, 0.0836040...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>medqa</td>\n",
       "      <td>An 8-year-old boy presents with a limp favorin...</td>\n",
       "      <td>{'A': 'Slipped capital femoral epiphysis', 'B'...</td>\n",
       "      <td>D</td>\n",
       "      <td>[30.875, 29.5, 27.75, 32.75, 26.75]</td>\n",
       "      <td>[0.12765265, 0.032275643, 0.0056086658, 0.8323...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>medqa</td>\n",
       "      <td>A 12-year-old African American is exposed to p...</td>\n",
       "      <td>{'A': 'IFN-gamma', 'B': 'IL-4', 'C': 'IL-17', ...</td>\n",
       "      <td>B</td>\n",
       "      <td>[23.375, 34.5, 22.875, 20.875, 23.375]</td>\n",
       "      <td>[1.47386145e-05, 0.9999603, 8.939422e-06, 1.20...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>E</td>\n",
       "      <td>medqa</td>\n",
       "      <td>A 76-year-old woman comes to the physician for...</td>\n",
       "      <td>{'A': 'Increased lung compliance', 'B': 'Incre...</td>\n",
       "      <td>A</td>\n",
       "      <td>[29.0, 29.625, 31.0, 28.375, 30.375]</td>\n",
       "      <td>[0.06780746, 0.12668101, 0.5010331, 0.03629472...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B</td>\n",
       "      <td>medqa</td>\n",
       "      <td>A 42-year-old woman comes to the physician for...</td>\n",
       "      <td>{'A': 'Order a transthoracic echocardiogram', ...</td>\n",
       "      <td>D</td>\n",
       "      <td>[29.125, 31.5, 31.125, 29.5, 28.25]</td>\n",
       "      <td>[0.047592025, 0.5116625, 0.35166016, 0.0692459...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>E</td>\n",
       "      <td>medqa</td>\n",
       "      <td>A 35-year-old male nurse presents to the emerg...</td>\n",
       "      <td>{'A': 'Dengue virus', 'B': 'Lymphocytic chorio...</td>\n",
       "      <td>E</td>\n",
       "      <td>[28.375, 29.125, 31.125, 28.625, 31.375]</td>\n",
       "      <td>[0.024919514, 0.05275461, 0.3898068, 0.0319972...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C</td>\n",
       "      <td>medqa</td>\n",
       "      <td>A 5-year-old boy is brought to the emergency d...</td>\n",
       "      <td>{'A': 'Diacylglycerol', 'B': 'Cyclic GMP', 'C'...</td>\n",
       "      <td>C</td>\n",
       "      <td>[27.375, 26.5, 34.25, 23.875, 23.375]</td>\n",
       "      <td>[0.0010317353, 0.00043009128, 0.99848807, 3.11...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B</td>\n",
       "      <td>medqa</td>\n",
       "      <td>A 19-year-old college student is brought to th...</td>\n",
       "      <td>{'A': 'Boerhaave syndrome', 'B': 'Mallory-Weis...</td>\n",
       "      <td>B</td>\n",
       "      <td>[33.0, 34.0, 24.75, 22.0, 21.5]</td>\n",
       "      <td>[0.2689206, 0.731002, 7.025781e-05, 4.4914314e...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  output dataset                                           question  \\\n",
       "0      D   medqa  An investigator is studying the frequency of p...   \n",
       "1      D   medqa  A 37-year-old woman presents to the occupation...   \n",
       "2      B   medqa  A 49-year-old man comes to the hospital for a ...   \n",
       "3      D   medqa  An 8-year-old boy presents with a limp favorin...   \n",
       "4      B   medqa  A 12-year-old African American is exposed to p...   \n",
       "5      E   medqa  A 76-year-old woman comes to the physician for...   \n",
       "6      B   medqa  A 42-year-old woman comes to the physician for...   \n",
       "7      E   medqa  A 35-year-old male nurse presents to the emerg...   \n",
       "8      C   medqa  A 5-year-old boy is brought to the emergency d...   \n",
       "9      B   medqa  A 19-year-old college student is brought to th...   \n",
       "\n",
       "                                             options reference  \\\n",
       "0  {'A': '30%', 'B': '15%', 'C': '95%', 'D': '99%...         B   \n",
       "1  {'A': 'Type I–anaphylactic hypersensitivity re...         D   \n",
       "2  {'A': 'Amylase of 200 U/L', 'B': 'Lymphocytosi...         E   \n",
       "3  {'A': 'Slipped capital femoral epiphysis', 'B'...         D   \n",
       "4  {'A': 'IFN-gamma', 'B': 'IL-4', 'C': 'IL-17', ...         B   \n",
       "5  {'A': 'Increased lung compliance', 'B': 'Incre...         A   \n",
       "6  {'A': 'Order a transthoracic echocardiogram', ...         D   \n",
       "7  {'A': 'Dengue virus', 'B': 'Lymphocytic chorio...         E   \n",
       "8  {'A': 'Diacylglycerol', 'B': 'Cyclic GMP', 'C'...         C   \n",
       "9  {'A': 'Boerhaave syndrome', 'B': 'Mallory-Weis...         B   \n",
       "\n",
       "                                     logits  \\\n",
       "0   [27.125, 27.25, 28.125, 27.125, 26.875]   \n",
       "1         [24.0, 23.5, 22.875, 34.0, 23.25]   \n",
       "2        [29.0, 29.875, 28.75, 28.25, 29.0]   \n",
       "3       [30.875, 29.5, 27.75, 32.75, 26.75]   \n",
       "4    [23.375, 34.5, 22.875, 20.875, 23.375]   \n",
       "5      [29.0, 29.625, 31.0, 28.375, 30.375]   \n",
       "6       [29.125, 31.5, 31.125, 29.5, 28.25]   \n",
       "7  [28.375, 29.125, 31.125, 28.625, 31.375]   \n",
       "8     [27.375, 26.5, 34.25, 23.875, 23.375]   \n",
       "9           [33.0, 34.0, 24.75, 22.0, 21.5]   \n",
       "\n",
       "                                             probits  correct  \n",
       "0  [0.15082432, 0.17090634, 0.409983, 0.15082432,...    False  \n",
       "1  [4.539498e-05, 2.7533446e-05, 1.4737591e-05, 0...     True  \n",
       "2  [0.17698982, 0.42457652, 0.13783981, 0.0836040...    False  \n",
       "3  [0.12765265, 0.032275643, 0.0056086658, 0.8323...     True  \n",
       "4  [1.47386145e-05, 0.9999603, 8.939422e-06, 1.20...     True  \n",
       "5  [0.06780746, 0.12668101, 0.5010331, 0.03629472...    False  \n",
       "6  [0.047592025, 0.5116625, 0.35166016, 0.0692459...    False  \n",
       "7  [0.024919514, 0.05275461, 0.3898068, 0.0319972...     True  \n",
       "8  [0.0010317353, 0.00043009128, 0.99848807, 3.11...     True  \n",
       "9  [0.2689206, 0.731002, 7.025781e-05, 4.4914314e...     True  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so our best document gives ~0.49 on our sample, and our worst ~0.35. What's our naive result?\n",
    "medqa_sample = medqa.sample(NUM_SAMPLE_QUESTIONS, random_state=42).to_dict(\"records\")\n",
    "naive = pd.DataFrame(batch_predict(model, tokenizer, medqa_sample))\n",
    "naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- [-0.06589192  0.00268912  0.01601555  0.00663549  0.04055174] A 19-year-old nulligravid woman comes to the physician because of irregular heavy menstrual bleeding\n",
      "+ [ 0.00318239  0.02664584  0.00916485  0.07712957 -0.11612266] A 25-year-old woman comes to the emergency department one hour after the sudden onset of diffuse abd\n",
      "- [ 0.00077816  0.26460293 -0.25649005  0.00307769 -0.01196865] A 33-year-old man is brought to the emergency department 20 minutes after he fell from the roof of h\n",
      "- [ 0.05930621  0.05129299  0.18535508  0.00694175 -0.30289602] A 52-year-old woman is accompanied by her husband to the emergency department with a severe occipita\n",
      "+ [-0.23684973 -0.01055806  0.01146453  0.02322807  0.21271518] An 15-year-old boy is brought to the emergency department after he passed out in the hallway. On pre\n",
      "- [ 6.2011462e-04 -8.0297589e-03  6.2527812e-01 -5.6853706e-01\n",
      " -4.9331389e-02] An otherwise healthy 16-year-old girl comes to the physician because she has not had a menstrual per\n",
      "- [-0.04156452  0.08455561  0.04639234 -0.12802774  0.03864432] Three days after undergoing coronary artery bypass surgery, a 72-year-old man has severe right upper\n"
     ]
    }
   ],
   "source": [
    "# where did our document hurt or help us vs the naive version?\n",
    "\n",
    "best_results = combined[combined['context'] == 'InternalMed_Harrison_12'].reset_index(drop=True).sort_values(by='question')\n",
    "naive_results = naive.sort_values(by='question')\n",
    "\n",
    "for ((_, best_row), (_,naive_row)) in zip(best_results.iterrows(), naive_results.iterrows()):\n",
    "  if best_row['correct'] == naive_row['correct']:\n",
    "    continue\n",
    "  if best_row['correct']:\n",
    "    print('+', best_row['probits'] - naive_row['probits'], best_row['question'][:100])\n",
    "  else:\n",
    "    print('-', best_row['probits'] - naive_row['probits'], best_row['question'][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pathlib\u001b[38;5;241m.\u001b[39mPath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./cache/embedding_ds.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m---> 44\u001b[0m     embedding_ds \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_finetune_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretriever\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmedqa\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmedqa\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msplit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_questions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocs_per_question\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     embedding_ds\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./cache/embedding_ds.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[10], line 15\u001b[0m, in \u001b[0;36mbuild_finetune_dataset\u001b[0;34m(model, tokenizer, retriever, training_set, num_questions, docs_per_question)\u001b[0m\n\u001b[1;32m     13\u001b[0m sample_df \u001b[38;5;241m=\u001b[39m training_set\u001b[38;5;241m.\u001b[39msample(num_questions, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, record \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(sample_df\u001b[38;5;241m.\u001b[39miterrows(), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(sample_df)):\n\u001b[0;32m---> 15\u001b[0m     docs, scores \u001b[38;5;241m=\u001b[39m \u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocs_per_question\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     naive_prediction \u001b[38;5;241m=\u001b[39m batch_predict(model, tokenizer, [record])[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     17\u001b[0m     naive_probits \u001b[38;5;241m=\u001b[39m naive_prediction[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprobits\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/medical-rag/src/medrag/utils.py:302\u001b[0m, in \u001b[0;36mRetrievalSystem.retrieve\u001b[0;34m(self, question, k, rrf_k)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m retriever_set \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrievers:\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m retriever \u001b[38;5;129;01min\u001b[39;00m retriever_set:\n\u001b[0;32m--> 302\u001b[0m         docs, scores \u001b[38;5;241m=\u001b[39m \u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m doc, score \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(docs, scores):\n\u001b[1;32m    304\u001b[0m             results\u001b[38;5;241m.\u001b[39mappend((retriever\u001b[38;5;241m.\u001b[39mname, doc, score))\n",
      "File \u001b[0;32m~/medical-rag/src/medrag/utils.py:224\u001b[0m, in \u001b[0;36mRetriever.retrieve\u001b[0;34m(self, question, k, **kwarg)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 224\u001b[0m         query_embed \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwarg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    226\u001b[0m     res_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39msearch(query_embed, k\u001b[38;5;241m=\u001b[39mk)\n\u001b[1;32m    227\u001b[0m     indices \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadatas[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m res_[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n",
      "File \u001b[0;32m~/medical-rag/src/medrag/utils.py:224\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 224\u001b[0m         query_embed \u001b[38;5;241m=\u001b[39m [\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m() \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_function\u001b[38;5;241m.\u001b[39mencode(question, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwarg)]\n\u001b[1;32m    226\u001b[0m     res_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39msearch(query_embed, k\u001b[38;5;241m=\u001b[39mk)\n\u001b[1;32m    227\u001b[0m     indices \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadatas[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m res_[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'cpu'"
     ]
    }
   ],
   "source": [
    "# Let's build a training dataset based on our document and a sample of our training data.\n",
    "\n",
    "\n",
    "def build_finetune_dataset(\n",
    "    model: transformers.PreTrainedModel,\n",
    "    tokenizer: transformers.PreTrainedTokenizer,\n",
    "    retriever: medrag.utils.RetrievalSystem,\n",
    "    training_set: pd.DataFrame,\n",
    "    num_questions: int,\n",
    "    docs_per_question: int,\n",
    "):\n",
    "    results = []\n",
    "    sample_df = training_set.sample(num_questions, random_state=42)\n",
    "    for _, record in tqdm.tqdm(sample_df.iterrows(), total=len(sample_df)):\n",
    "        docs, scores = retriever.retrieve(record[\"question\"], k=docs_per_question)\n",
    "        naive_prediction = batch_predict(model, tokenizer, [record])[0]\n",
    "        naive_probits = naive_prediction[\"probits\"]\n",
    "        predictions = batch_predict(\n",
    "            model, tokenizer, [record], context=[doc[\"content\"] for doc in docs]\n",
    "        )\n",
    "\n",
    "        for i, row in enumerate(predictions):\n",
    "            doc_probits = row[\"probits\"]\n",
    "            diff_probits = doc_probits - naive_probits\n",
    "            reference_idx = ord(row[\"reference\"]) - ord(\"A\")\n",
    "\n",
    "            correct_diff = diff_probits[reference_idx]\n",
    "\n",
    "            results.append(\n",
    "                {\n",
    "                    \"question\": row[\"question\"],\n",
    "                    \"document\": docs[i][\"content\"],\n",
    "                    \"reference\": row[\"reference\"],\n",
    "                    \"options\": row[\"options\"],\n",
    "                    \"diff\": correct_diff,\n",
    "                    \"naive_answer\": naive_prediction[\"answer\"],\n",
    "                    \"naive_score\": naive_probits[reference_idx],\n",
    "                    \"context_score\": doc_probits[reference_idx],\n",
    "                }\n",
    "            )\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "if not pathlib.Path(\"./cache/embedding_ds.csv\").exists():\n",
    "    embedding_ds = build_finetune_dataset(\n",
    "        model,\n",
    "        tokenizer,\n",
    "        retriever,\n",
    "        medqa[medqa[\"split\"] == \"train\"],\n",
    "        num_questions=1000,\n",
    "        docs_per_question=20,\n",
    "    )\n",
    "    embedding_ds.to_csv(\"./cache/embedding_ds.csv\", index=False)\n",
    "else:\n",
    "    embedding_ds = pd.read_csv(\"./cache/embedding_ds.csv\")\n",
    "\n",
    "embedding_ds.sort_values(by=\"diff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/mambaforge/envs/tensorml/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['sentence1', 'sentence2', 'label'],\n",
      "    num_rows: 8192\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1401' max='1536' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1401/1536 03:35 < 00:20, 6.48 it/s, Epoch 2.73/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearson Cosine</th>\n",
       "      <th>Spearman Cosine</th>\n",
       "      <th>Pearson Manhattan</th>\n",
       "      <th>Spearman Manhattan</th>\n",
       "      <th>Pearson Euclidean</th>\n",
       "      <th>Spearman Euclidean</th>\n",
       "      <th>Pearson Dot</th>\n",
       "      <th>Spearman Dot</th>\n",
       "      <th>Pearson Max</th>\n",
       "      <th>Spearman Max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.122073</td>\n",
       "      <td>-0.024736</td>\n",
       "      <td>-0.022323</td>\n",
       "      <td>-0.026001</td>\n",
       "      <td>-0.040640</td>\n",
       "      <td>-0.026840</td>\n",
       "      <td>-0.009170</td>\n",
       "      <td>-0.014260</td>\n",
       "      <td>-0.018472</td>\n",
       "      <td>-0.014260</td>\n",
       "      <td>-0.009170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.122063</td>\n",
       "      <td>-0.024399</td>\n",
       "      <td>-0.022323</td>\n",
       "      <td>-0.024522</td>\n",
       "      <td>-0.022323</td>\n",
       "      <td>-0.025535</td>\n",
       "      <td>-0.022323</td>\n",
       "      <td>-0.008420</td>\n",
       "      <td>-0.004954</td>\n",
       "      <td>-0.008420</td>\n",
       "      <td>-0.004954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>4.199000</td>\n",
       "      <td>4.122064</td>\n",
       "      <td>-0.025142</td>\n",
       "      <td>-0.022323</td>\n",
       "      <td>-0.025130</td>\n",
       "      <td>-0.022323</td>\n",
       "      <td>-0.025955</td>\n",
       "      <td>-0.022323</td>\n",
       "      <td>0.024533</td>\n",
       "      <td>0.021026</td>\n",
       "      <td>0.024533</td>\n",
       "      <td>0.021026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>4.199000</td>\n",
       "      <td>4.122063</td>\n",
       "      <td>-0.025496</td>\n",
       "      <td>-0.022421</td>\n",
       "      <td>-0.024824</td>\n",
       "      <td>-0.030123</td>\n",
       "      <td>-0.025540</td>\n",
       "      <td>-0.030124</td>\n",
       "      <td>-0.010070</td>\n",
       "      <td>-0.007111</td>\n",
       "      <td>-0.010070</td>\n",
       "      <td>-0.007111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>4.135000</td>\n",
       "      <td>4.122063</td>\n",
       "      <td>-0.024072</td>\n",
       "      <td>-0.023809</td>\n",
       "      <td>-0.024507</td>\n",
       "      <td>-0.023261</td>\n",
       "      <td>-0.025352</td>\n",
       "      <td>-0.023261</td>\n",
       "      <td>0.018180</td>\n",
       "      <td>0.015362</td>\n",
       "      <td>0.018180</td>\n",
       "      <td>0.015362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>4.135000</td>\n",
       "      <td>4.122063</td>\n",
       "      <td>-0.024936</td>\n",
       "      <td>-0.024144</td>\n",
       "      <td>-0.025731</td>\n",
       "      <td>-0.019280</td>\n",
       "      <td>-0.025573</td>\n",
       "      <td>-0.018983</td>\n",
       "      <td>-0.001216</td>\n",
       "      <td>-0.004849</td>\n",
       "      <td>-0.001216</td>\n",
       "      <td>-0.004849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cb2bc27b20042d383862b6e8c7f4e36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 60\u001b[0m\n\u001b[1;32m     39\u001b[0m training_args \u001b[38;5;241m=\u001b[39m SentenceTransformerTrainingArguments(\n\u001b[1;32m     40\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./cache/medcpt-embedding-model\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     41\u001b[0m     eval_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msteps\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m     bf16\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     50\u001b[0m )\n\u001b[1;32m     52\u001b[0m trainer \u001b[38;5;241m=\u001b[39m SentenceTransformerTrainer(\n\u001b[1;32m     53\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     54\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     58\u001b[0m     evaluator\u001b[38;5;241m=\u001b[39mevaluator,\n\u001b[1;32m     59\u001b[0m )\n\u001b[0;32m---> 60\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/transformers/trainer.py:1885\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1883\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/transformers/trainer.py:2291\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2288\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[1;32m   2289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2291\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2292\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2293\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/transformers/trainer.py:2721\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2719\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2720\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_evaluate:\n\u001b[0;32m-> 2721\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2722\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   2724\u001b[0m     \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/sentence_transformers/trainer.py:382\u001b[0m, in \u001b[0;36mSentenceTransformerTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(eval_dataset, DatasetDict) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    381\u001b[0m     eval_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_dataset_name_column(eval_dataset)\n\u001b[0;32m--> 382\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/transformers/trainer.py:3572\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3569\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3571\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3572\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3573\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3574\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3575\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   3576\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   3577\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3578\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3579\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3580\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3582\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/sentence_transformers/trainer.py:414\u001b[0m, in \u001b[0;36mSentenceTransformerTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m nullcontext() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_local_process_zero() \u001b[38;5;28;01melse\u001b[39;00m disable_logging(logging\u001b[38;5;241m.\u001b[39mINFO):\n\u001b[0;32m--> 414\u001b[0m     evaluator_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(evaluator_metrics, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    416\u001b[0m     evaluator_metrics \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluator\u001b[39m\u001b[38;5;124m\"\u001b[39m: evaluator_metrics}\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/sentence_transformers/evaluation/EmbeddingSimilarityEvaluator.py:159\u001b[0m, in \u001b[0;36mEmbeddingSimilarityEvaluator.__call__\u001b[0;34m(self, model, output_path, epoch, steps)\u001b[0m\n\u001b[1;32m    156\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmbeddingSimilarityEvaluator: Evaluating the model on the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dataset\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout_txt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m nullcontext() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtruncate_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m model\u001b[38;5;241m.\u001b[39mtruncate_sentence_embeddings(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtruncate_dim):\n\u001b[0;32m--> 159\u001b[0m     embeddings1 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msentences1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_to_numpy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprecision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormalize_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m     embeddings2 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentences2,\n\u001b[1;32m    169\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    173\u001b[0m         normalize_embeddings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision),\n\u001b[1;32m    174\u001b[0m     )\n\u001b[1;32m    175\u001b[0m \u001b[38;5;66;03m# Binary and ubinary embeddings are packed, so we need to unpack them for the distance metrics\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:517\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    514\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate(extra_features)\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 517\u001b[0m     out_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhpu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    519\u001b[0m         out_features \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(out_features)\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/accelerate/utils/operations.py:822\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 822\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/accelerate/utils/operations.py:810\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 810\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/torch/amp/autocast_mode.py:16\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 16\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/sentence_transformers/models/Transformer.py:118\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[1;32m    116\u001b[0m     trans_features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 118\u001b[0m output_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m output_tokens \u001b[38;5;241m=\u001b[39m output_states[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    121\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_tokens, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]})\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:1137\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1130\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1137\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1138\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1149\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1150\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:690\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    679\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    680\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    681\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    687\u001b[0m         output_attentions,\n\u001b[1;32m    688\u001b[0m     )\n\u001b[1;32m    689\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 690\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    700\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    701\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:580\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    570\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    577\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    579\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 580\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    587\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:510\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    502\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    508\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    509\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 510\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    519\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    520\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:407\u001b[0m, in \u001b[0;36mBertSdpaSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    405\u001b[0m     key_layer, value_layer \u001b[38;5;241m=\u001b[39m past_key_value\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 407\u001b[0m     key_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_states\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    408\u001b[0m     value_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue(current_states))\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cross_attention:\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b4bb53447d54931b479b37bbb55a88f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/640 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c15e18a24c8748dabd600f14ccb49129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/640 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'pearson_cosine': -0.06810226225370059,\n",
       " 'spearman_cosine': -0.05559002341330524,\n",
       " 'pearson_manhattan': -0.06872582105690865,\n",
       " 'spearman_manhattan': -0.06020936189466997,\n",
       " 'pearson_euclidean': -0.06363380139335643,\n",
       " 'spearman_euclidean': -0.05553909496020786,\n",
       " 'pearson_dot': -0.07419404731340484,\n",
       " 'spearman_dot': -0.07367379127064597,\n",
       " 'pearson_max': -0.06363380139335643,\n",
       " 'spearman_max': -0.05553909496020786}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.show_progress_bar=True\n",
    "evaluator(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
